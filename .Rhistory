mutate(individual = bat) %>%
dplyr::select(group, individual, duration:segments)
# tole post-intro bats
tole_post <- d3 %>%
filter(group == "tole2") %>%
mutate(individual = bat) %>%
dplyr::select(group, individual, duration:segments)
# las pavas bats
lp <- d3 %>%
filter(group == "lp") %>%
mutate(individual = bat) %>%
dplyr::select(group, individual, duration:segments)
# get all PRE-INTRO dyadic distances
pre <- rbind(tole_pre,lp)
# classify calls to bat using a single dfa without cross validation
dfa_pre <- lda(individual ~
duration+
meanfreq+
sd+
freq.median+
freq.Q25+
freq.Q75+
freq.IQR+
time.median+
time.Q25+
time.Q75+
time.IQR+
skew+
kurt+
sp.ent+
time.ent+
entropy+
sfm+
meandom+
mindom+
maxdom+
dfrange+
modindx+
startdom+
enddom+
dfslope+
meanpeakf+
peakf+
maxslope+
minslope+
abs_minslope+
pos_slopes+
neg_slopes+
turns+
meanslope+
segments,
CV= F,
data=pre)
# get vocal distance as Mahalanobis distance between group centroids
pre_distance <- as.matrix(dist(dfa_pre$means %*% dfa_pre$scaling))
# get all POST-INTRO dyadic distances
post <- rbind(tole_post,lp)
# classify calls to bat using a single dfa without cross validation
dfa_post <- lda(individual ~
duration+
meanfreq+
sd+
freq.median+
freq.Q25+
freq.Q75+
freq.IQR+
time.median+
time.Q25+
time.Q75+
time.IQR+
skew+
kurt+
sp.ent+
time.ent+
entropy+
sfm+
meandom+
mindom+
maxdom+
dfrange+
modindx+
startdom+
enddom+
dfslope+
meanpeakf+
peakf+
maxslope+
minslope+
abs_minslope+
pos_slopes+
neg_slopes+
turns+
meanslope+
segments,
CV= F,
data=post)
#* make matrix containing change in distance (convergence) ----
# get vocal distance as Mahalanobis distance between group centroids
post_distance <- as.matrix(dist(dfa_post$means %*% dfa_post$scaling))
# reorder matrices
order <- c(unique(tole_pre$individual), unique(lp$individual))
pre_dist <- reorder_mat(pre_distance, order)
post_dist <- reorder_mat(post_distance, order)
diff <- pre_dist - post_dist
#* make familiar vs introduced matrix ----
lp_bats <- unique(lp$individual)
tole_bats <- unique(tole_pre$individual)
a <- matrix(nrow = 12, ncol = 12)
col1 <- c(rep(0,times=7),rep(1,times=5))
col2 <- c(rep(1,times=7),rep(0,times=5))
v <- c(rep(col1,times=7),rep(col2,times=5))
a[,] <- v
diag(a) <- NA
rownames(a) <- c(tole_bats,lp_bats)
colnames(a) <- c(tole_bats,lp_bats)
#* Mantel test ----
mantel(diff, a, na.rm=T, method= 'spearman')
# get misclassification rates for pre- and post- intro ----
# Mundry's program requires the following:
# one column for test factor (groups)
# one column for control factor (individuals)
# however many variable columns
# variables should be only numbers, group and individual can be named
# NO missing values
# will take smallest number of calls
#for nested design, data do not have to be balanced
#tests for difference between groups ('testfac')
#groups and subjects ('contrfac') have to numbered consecutively and with integers beginning with 1
# make into function
pDFA <- function(xdata, test_fac, contr_fac, variables, n.sel = 100, nperm = 1000) {
if (is.factor(test_fac)==F) {test_fac=as.factor(test_fac)}
model=paste("lda(test_fac~",variables,", prior=pr_prob, subset=sel.index, data=xdata)",sep="")
f.table=as.data.frame(table(contr_fac))
ncf.levels=nrow(f.table)
ntf.levels=nrow(table(test_fac))
pr_prob=rep(1/ntf.levels, ntf.levels)#define prior probabilities to be equal for either of two groups
#get number of cases per subject (level of contrfac):
#get number of calls to select per subject (subject)
n.to.sel=min(f.table$Freq)
#set number of random selections original classification rate should be based on:
ur.c.val=0
ur.sel=0
number=(1:nrow(xdata))
#get assignment of subjects to groups
gr=c()
subj.gr= table(contr_fac,test_fac)
subject=rownames(subj.gr)
for (i in 1:ncf.levels){
for (k in 1:ntf.levels){
if (subj.gr[i,k]>0) {gr=c(gr,colnames(subj.gr)[k])}
}
}
for (k in 1:n.sel){
#make random selection of same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ur.sel=ur.sel+sum((test_fac==pred)[sel==1])
ur.c.val= ur.c.val+ sum((test_fac==pred)[sel==0])
}
#save number of correctly classified calls in variable 'orig.res':
ur.sel= ur.sel/ n.sel
ur.c.val= ur.c.val/ n.sel
#set P-value to 1 (since original data should be treated as 1 permutation):
p.sel=1
p.c.val=1
all.corr=matrix(NA, nrow=nperm, ncol=2)
all.corr[1,1]=ur.sel
all.corr[1,2]=ur.c.val
if (length(gr)==ncf.levels){
for (k in 1:(nperm-1)){
#randomize subjects' assignments to groups:
r.gr=sample(gr,length(gr), replace=F)
for (i in 1:length(subject)){
test_fac[contr_fac==subject[i]]=r.gr[i]
}
#make random selection or same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ran.sel= sum((test_fac==pred)[sel==1])
ran.c.val= sum((test_fac==pred)[sel==0])
if (ran.sel>=ur.sel){p.sel = p.sel + 1}
if (ran.c.val>= ur.c.val){p.c.val= p.c.val + 1}
all.corr[k+1,1]=ran.sel
all.corr[k+1,2]=ran.c.val
}
what=c("N correctly assigned, original, selected", "P for selected", "N correctly assigned, original, cross-validated", "P for cross-validated", "N groups (levels of test factor)", "N subjects (levels of control factor)", "N cases total", "N cases selected per subject","N selected total", "N permutations","N random selections")
value=c(ur.sel,p.sel/nperm,ur.c.val,p.c.val/nperm,ntf.levels,ncf.levels,nrow(xdata),n.to.sel,n.to.sel*ncf.levels,nperm,n.sel)
result=data.frame(what,value)
}else{
result="at least one subject is member of two groups; no test done"
}
result
write.table(result,file=paste("/Users/jkvrtilek/Desktop/OSU/PhD/GitHub/call-convergence-2025/06_similarity_over_time/",levels(test_fac)[1],"_",levels(test_fac)[2],sep=""),row.names=F,col.names=T)
all.corr[,1]#comprises the number correctly classified selected objects for all
#permutations (with the first value being that for the original data)
all.corr[,2]#same for the cross-validated objects
hist(all.corr[,1])#shows the frequency distribution
print(result)
}
#### pre-introduction Tole bats vs post-intro Las Pavas bats
xdata <- pre
test_fac <- as.factor(as.character(xdata$group))
contr_fac <- as.factor(as.character(xdata$individual))
variables <- paste(colnames(pre)[3:ncol(pre)], collapse = "+")
pDFA(xdata, test_fac, contr_fac, variables)
#### post-introduction Tole bats vs post-intro Las Pavas bats
xdata <- post
test_fac <- as.factor(as.character(xdata$group))
contr_fac <- as.factor(as.character(xdata$individual))
variables <- paste(colnames(post)[3:ncol(post)], collapse = "+")
pDFA(xdata, test_fac, contr_fac, variables)
3016.960/3912.000
786.070/1164.000
# make plot
p <- rec_dates %>%
ggplot(aes(x=date, y=bat, group=bat)) +
facet_wrap(~CaptureSite, scales = "free_y", ncol = 1) +
geom_point(aes(color = capture.site)) +
geom_line() +
scale_x_date(date_labels = "%b %Y", breaks = "3 months") +
scale_color_manual(values = c("#0f2d59","#3eb7c7")) +
guides(color=guide_legend("Bat Origin")) +
geom_vline(xintercept = as.numeric(smallcage), color = "red", linetype = "dashed") +
geom_vline(xintercept = as.numeric(largecage), color = "red") +
ylab("individual bats") +
xlab("recording dates") +
theme_bw() +
theme(axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
legend.position = "none",
plot.title = element_text(hjust = 0.5, size = 24),
axis.text.x = element_text(size = 16),
axis.title.x = element_text(size = 20),
axis.title.y = element_text(size = 20),
strip.text.x = element_text(size = 16)) +
geom_text(data = labels_lp, aes(label = bat), nudge_x = +15) +
geom_text(data = labels_tole, aes(label = bat), nudge_x = +15)
# save plot
ggsave(
"/06_similarity_over_time/contact_plot.pdf",
plot = p,
scale = 1,
width = 6,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
getwd()
# save plot
ggsave(
"06_similarity_over_time/contact_plot.pdf",
plot = p,
scale = 1,
width = 6,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
# save plot
ggsave(
"06_similarity_over_time/recording_dates.pdf",
plot = p,
scale = 1,
width = 8,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
load("/Users/jkvrtilek/Desktop/OSU/PhD/GitHub/call-convergence-2025/05_fit_models/model_fit_workspace_2024-10-09_1426.Rdata")
# get relevant data to plot
t <-
d %>%
filter(both_adult) %>%
filter(dyad.sex== "female") %>%
filter(kinship <0.05| is.na(kinship))
# plot treatment categories for non-kin
t %>%
ggplot(aes(x=treatment_label, y=sim, color= treatment_label))+
geom_violin()+
geom_boxplot(width=0.1)+
geom_jitter(alpha=0.1, height=0, width=0.1)+
ylab("contact call similarity")+
xlab("familiarity level")+
scale_colour_brewer(palette= "Dark2")+
theme_bw()+
theme(legend.position= "none")
# plot means and 95% CIs
means <-
t %>%
filter(!is.na(treatment_label)) %>%
boot_ci2(x = .$treatment_label, y= .$sim)
points <-
t %>%
filter(!is.na(treatment_label)) %>%
mutate(effect= treatment_label)
# plot with raw data
(p3 <-
means %>%
ggplot(aes(x=effect, y=mean, color=effect))+
geom_jitter(data= points, aes(y= sim), size=1, alpha=0.5, height=0, width=0.1)+
geom_boxplot(data= points, aes(y= sim), width=0.1, fill=NA, color="black", outlier.shape=NA)+
geom_point(position = position_nudge(x = 0.25), size=1)+
geom_errorbar(aes(ymin=low, ymax=high, width=.1), position = position_nudge(x = 0.25), size=1)+
ylab("contact call similarity")+
xlab("familiarity level")+
scale_colour_brewer(palette= "Dark2")+
geom_hline(yintercept = means[1,"mean"], col = "#1B9E77")+
theme_bw()+
theme(legend.position = "none"))
# plot without raw data
(p4 <-
means %>%
ggplot(aes(x=effect, y=mean, color=effect))+
geom_point(size=3)+
geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1)+
ylab("contact call similarity")+
xlab(" \nfamiliarity level")+
scale_colour_brewer(palette= "Dark2")+
geom_hline(yintercept = means[1,"mean"], col = "#1B9E77")+
theme_bw()+
theme(axis.text.x = element_text(size = 11))+
theme(legend.position = "none"))
# combine plots
# remove x-axis from top plot
p3a <-
p3+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
(p5 <- p3a/p4)
# save plot
ggsave(
"familiarity_plot.pdf",
plot = p5,
scale = 1,
width = 9,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
# get relevant data to analyze
# get pairs of nonkin females that never met (treatment rank 1) and ones that were introduced (treatment rank 3)
# compare those two groups treatment rank 1 vs 3
t <-
d %>%
filter(both_adult) %>%
# get female dyads
filter(dyad.sex== "female") %>%
# get nonkin dyads
filter(kinship == 0) %>%
# get bats that never met or were introduced
filter(treatment_rank == 1 | treatment_rank == 3 ) %>%
# label familiar as TRUE/FALSE
mutate(fam = treatment_rank > 1)
# fit model with nonkin females that were introduced together or not
fit.intro <-
brm(sim ~
fam +
(1|mm(bat1,bat2)),
data = t,
family = "beta",
cores = nchains,
chains = nchains,
iter = chain_length,
warmup = warmup_length)
# check model
pp_check(fit.intro, ndraws=100)
summary(fit.intro)
remove(t)
#***plot contact effect-------------
# get relevant data
# pairs of female bats in the same group
t <-
d %>%
# exclude pairs with bats that could never groom
filter(!is.na(contact.lograte)) %>%
filter(kinship <0.05) %>%
filter(both_adult) %>%
filter(dyad.sex== "female") %>%
mutate(colony= substring(study_site,1,4)) %>%
mutate(captured.together= case_when(
study_site == "2014_US" ~ TRUE,
study_site == "2017_different sites" ~ FALSE,
study_site == "2019_different sites" ~ FALSE,
study_site == "2017_TL" ~ TRUE,
study_site == "2019_TL" ~ TRUE,
study_site == "2019_LB" ~ TRUE,
study_site == "2019_CH" ~ TRUE,
study_site == "2017_LP" ~ TRUE)) %>%
mutate(contact= contact.rate> 0)
# plot
(p <-
t %>%
mutate(`captured together` = captured.together) %>%
ggplot(aes(x=contact.lograte, y=sim,
color=`captured together`, shape=`captured together`, linetype= `captured together`))+
facet_wrap(~colony, scales= "free_x")+
geom_point(size=2)+
geom_smooth(method="lm")+
xlab("within-group contact log rate")+
ylab("contact call similarity")+
scale_color_brewer(palette= "Dark2")+
theme_bw()+
theme(legend.position = "top"))
# save plot
ggsave(
"contact_plot.pdf",
plot = p,
scale = 1,
width = 6,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
remove(t)
# get relevant data to plot
t <-
d %>%
filter(both_adult) %>%
filter(dyad.sex== "female") %>%
filter(kinship <0.05| is.na(kinship))
# plot treatment categories for non-kin
t %>%
ggplot(aes(x=treatment_label, y=sim, color= treatment_label))+
geom_violin()+
geom_boxplot(width=0.1)+
geom_jitter(alpha=0.1, height=0, width=0.1)+
ylab("contact call similarity")+
xlab("familiarity level")+
scale_colour_brewer(palette= "Dark2")+
theme_bw()+
theme(legend.position= "none")
# plot means and 95% CIs
means <-
t %>%
filter(!is.na(treatment_label)) %>%
boot_ci2(x = .$treatment_label, y= .$sim)
points <-
t %>%
filter(!is.na(treatment_label)) %>%
mutate(effect= treatment_label)
# plot with raw data
(p3 <-
means %>%
ggplot(aes(x=effect, y=mean, color=effect))+
geom_jitter(data= points, aes(y= sim), size=1, alpha=0.5, height=0, width=0.1)+
geom_boxplot(data= points, aes(y= sim), width=0.1, fill=NA, color="black", outlier.shape=NA)+
geom_point(position = position_nudge(x = 0.25), size=1)+
geom_errorbar(aes(ymin=low, ymax=high, width=.1), position = position_nudge(x = 0.25), size=1)+
ylab("contact call similarity")+
xlab("familiarity level")+
scale_colour_brewer(palette= "Dark2")+
geom_hline(yintercept = means[1,"mean"], col = "#1B9E77")+
theme_bw()+
theme(legend.position = "none"))
# plot without raw data
(p4 <-
means %>%
ggplot(aes(x=effect, y=mean, color=effect))+
geom_point(size=3)+
geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1)+
ylab("contact call similarity")+
xlab(" \nfamiliarity level")+
scale_colour_brewer(palette= "Dark2")+
geom_hline(yintercept = means[1,"mean"], col = "#1B9E77")+
theme_bw()+
theme(axis.text.x = element_text(size = 11))+
theme(legend.position = "none"))
# combine plots
# remove x-axis from top plot
p3a <-
p3+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
(p5 <- p3a/p4)
# save plot
ggsave(
"familiarity_plot.pdf",
plot = p5,
scale = 1,
width = 9,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
# save plot
ggsave(
"familiarity_plot.svg",
plot = p5,
scale = 1,
width = 9,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
# save plot
ggsave(
"familiarity_plot.pdf",
plot = p5,
scale = 1,
width = 9,
height = 5,
units = c("in", "cm", "mm", "px"),
dpi = 300)
